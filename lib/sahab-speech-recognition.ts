// Sahab Speech Recognition Service
export class SahabSpeechRecognition {
    private mediaRecorder: MediaRecorder | null = null;
    private audioChunks: Blob[] = [];
    private isRecording = false;
    private stream: MediaStream | null = null;
    private readonly gatewayToken = 'eyJhbGciOiJIUzI1NiJ9.eyJzeXN0ZW0iOiJzYWhhYiIsImNyZWF0ZVRpbWUiOiIxNDA0MDYwNjIzMjM1MDA3MCIsInVuaXF1ZUZpZWxkcyI6eyJ1c2VybmFtZSI6ImU2ZTE2ZWVkLTkzNzEtNGJlOC1hZTBiLTAwNGNkYjBmMTdiOSJ9LCJncm91cE5hbWUiOiIxMmRhZWM4OWE4M2EzZWU2NWYxZjMzNTFlMTE4MGViYiIsImRhdGEiOnsic2VydmljZUlEIjoiOWYyMTU2NWMtNzFmYS00NWIzLWFkNDAtMzhmZjZhNmM1YzY4IiwicmFuZG9tVGV4dCI6Ik9WVVZyIn19.sEUI-qkb9bT9eidyrj1IWB5Kwzd8A2niYrBwe1QYfpY';

    constructor() {
        console.log('ğŸ¤ Sahab Speech Recognition Service initialized');
    }

    // Check if browser supports audio recording
    isSupported(): boolean {
        return !!(navigator.mediaDevices &&
            navigator.mediaDevices.getUserMedia &&
            window.MediaRecorder);
    }

    // Start recording audio
    async startRecording(): Promise<void> {
        console.log('ğŸ¤ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ø±ÙˆØ¹ Ø¶Ø¨Ø·...');

        if (this.isRecording) {
            console.warn('âš ï¸ Ø¶Ø¨Ø· Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ø¯Ø± Ø¬Ø±ÛŒØ§Ù† Ø§Ø³Øª');
            throw new Error('Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ø¶Ø¨Ø· Ø¯Ø± Ø¬Ø±ÛŒØ§Ù† Ø§Ø³Øª');
        }

        if (!this.isSupported()) {
            console.error('âŒ Ù…Ø±ÙˆØ±Ú¯Ø± Ø§Ø² Ø¶Ø¨Ø· Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒÚ©Ù†Ø¯');
            throw new Error('Ù…Ø±ÙˆØ±Ú¯Ø± Ø´Ù…Ø§ Ø§Ø² Ø¶Ø¨Ø· ØµØ¯Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒÚ©Ù†Ø¯');
        }

        try {
            console.log('ğŸ¤ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ†...');

            // Get microphone access
            this.stream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true,
                    sampleRate: 16000
                }
            });

            console.log('âœ… Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ù…ÙˆÙÙ‚');

            // Clear previous chunks
            this.audioChunks = [];

            // Create MediaRecorder with appropriate format
            const options = {
                mimeType: 'audio/webm;codecs=opus'
            };

            console.log('ğŸ”§ Ø¨Ø±Ø±Ø³ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ...');

            // Fallback mime types
            if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                console.log('âš ï¸ webm/opus Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø±...');
                if (MediaRecorder.isTypeSupported('audio/mp4')) {
                    options.mimeType = 'audio/mp4';
                    console.log('âœ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ±Ù…Øª mp4');
                } else if (MediaRecorder.isTypeSupported('audio/wav')) {
                    options.mimeType = 'audio/wav';
                    console.log('âœ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ±Ù…Øª wav');
                } else {
                    delete (options as any).mimeType;
                    console.log('âš ï¸ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ±Ù…Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ù…Ø±ÙˆØ±Ú¯Ø±');
                }
            } else {
                console.log('âœ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ±Ù…Øª webm/opus');
            }

            this.mediaRecorder = new MediaRecorder(this.stream, options);
            console.log('âœ… MediaRecorder Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯ Ø¨Ø§ ÙØ±Ù…Øª:', this.mediaRecorder.mimeType);

            // Handle data available
            this.mediaRecorder.ondataavailable = (event) => {
                console.log('ğŸ“Š Ø¯Ø§Ø¯Ù‡ ØµÙˆØªÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯:', event.data.size, 'bytes');
                if (event.data.size > 0) {
                    this.audioChunks.push(event.data);
                }
            };

            this.mediaRecorder.onstart = () => {
                console.log('ğŸ¤ Ø¶Ø¨Ø· Ø´Ø±ÙˆØ¹ Ø´Ø¯');
            };

            this.mediaRecorder.onstop = () => {
                console.log('â¹ï¸ Ø¶Ø¨Ø· Ù…ØªÙˆÙ‚Ù Ø´Ø¯');
            };

            this.mediaRecorder.onerror = (event) => {
                console.error('âŒ Ø®Ø·Ø§ Ø¯Ø± MediaRecorder:', event);
            };

            // Start recording
            this.mediaRecorder.start(1000);
            this.isRecording = true;

            console.log('ğŸ¤ Ø´Ø±ÙˆØ¹ Ø¶Ø¨Ø· ØµØ¯Ø§ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ù‡Ø§Ø¨...');

        } catch (error) {
            console.error('âŒ Ø®Ø·Ø§ Ø¯Ø± Ø´Ø±ÙˆØ¹ Ø¶Ø¨Ø·:', {
                error: error,
                message: error instanceof Error ? error.message : 'Ø®Ø·Ø§ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ',
                name: error instanceof Error ? error.name : undefined
            });
            throw new Error('Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ†: ' + (error instanceof Error ? error.message : 'Ø®Ø·Ø§ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ'));
        }
    }

    // Stop recording and return audio blob
    async stopRecording(): Promise<Blob> {
        console.log('â¹ï¸ Ø¯Ø±Ø®ÙˆØ§Ø³Øª ØªÙˆÙ‚Ù Ø¶Ø¨Ø·...');

        if (!this.isRecording || !this.mediaRecorder) {
            console.error('âŒ Ø¶Ø¨Ø· Ø¯Ø± Ø¬Ø±ÛŒØ§Ù† Ù†ÛŒØ³Øª');
            throw new Error('Ø¶Ø¨Ø· Ø¯Ø± Ø¬Ø±ÛŒØ§Ù† Ù†ÛŒØ³Øª');
        }

        console.log('ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ chunks Ø¶Ø¨Ø· Ø´Ø¯Ù‡:', this.audioChunks.length);

        return new Promise((resolve, reject) => {
            if (!this.mediaRecorder) {
                reject(new Error('MediaRecorder not available'));
                return;
            }

            this.mediaRecorder.onstop = () => {
                console.log('â¹ï¸ MediaRecorder Ù…ØªÙˆÙ‚Ù Ø´Ø¯');
                console.log('ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ù†Ù‡Ø§ÛŒÛŒ chunks:', this.audioChunks.length);

                const totalSize = this.audioChunks.reduce((sum, chunk) => sum + chunk.size, 0);
                console.log('ğŸ“Š Ø­Ø¬Ù… Ú©Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ:', totalSize, 'bytes');

                const audioBlob = new Blob(this.audioChunks, {
                    type: this.mediaRecorder?.mimeType || 'audio/webm'
                });

                console.log('ğŸ“ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ù†Ù‡Ø§ÛŒÛŒ:', {
                    size: audioBlob.size,
                    type: audioBlob.type
                });

                // Clean up
                this.cleanup();

                console.log('âœ… Ø¶Ø¨Ø· Ù…ØªÙˆÙ‚Ù Ø´Ø¯ØŒ Ø­Ø¬Ù… ÙØ§ÛŒÙ„:', audioBlob.size, 'bytes');
                resolve(audioBlob);
            };

            this.mediaRecorder.onerror = (event) => {
                console.error('âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¶Ø¨Ø·:', event);
                this.cleanup();
                reject(new Error('Ø®Ø·Ø§ Ø¯Ø± Ø¶Ø¨Ø· ØµØ¯Ø§'));
            };

            console.log('â¹ï¸ Ø§Ø±Ø³Ø§Ù„ Ø¯Ø³ØªÙˆØ± ØªÙˆÙ‚Ù Ø¨Ù‡ MediaRecorder...');
            this.mediaRecorder.stop();
            this.isRecording = false;
        });
    }

    // Convert audio blob to base64
    private async audioToBase64(audioBlob: Blob): Promise<string> {
        return new Promise((resolve, reject) => {
            const reader = new FileReader();
            reader.onload = () => {
                const result = reader.result as string;
                // Remove data URL prefix (data:audio/webm;base64,)
                const base64 = result.split(',')[1];
                resolve(base64);
            };
            reader.onerror = () => reject(new Error('Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ ÙØ§ÛŒÙ„ Ø¨Ù‡ base64'));
            reader.readAsDataURL(audioBlob);
        });
    }

    // Send audio to Sahab API and get text (using backend endpoint)
    async convertToText(audioBlob: Blob): Promise<string> {
        try {
            console.log('ğŸ”„ Ø´Ø±ÙˆØ¹ ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ backend API...');
            console.log('ğŸ“ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ:', {
                size: audioBlob.size,
                type: audioBlob.type
            });

            if (audioBlob.size === 0) {
                throw new Error('ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª');
            }

            console.log('ğŸ”„ ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ base64...');
            const base64Audio = await this.audioToBase64(audioBlob);
            console.log('âœ… ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ base64 Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ØŒ Ø·ÙˆÙ„:', base64Audio.length);

            console.log('ğŸ“¤ Ø§Ø±Ø³Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ backend API...');

            // Use our backend API instead of direct Sahab call
            const response = await fetch('/api/voice-analysis/sahab-speech-recognition', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                credentials: 'include',
                body: JSON.stringify({
                    data: base64Audio,
                    language: 'fa'
                })
            });

            console.log('ğŸ“¥ Ù¾Ø§Ø³Ø® backend API Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯:', {
                status: response.status,
                statusText: response.statusText,
                ok: response.ok
            });

            if (!response.ok) {
                const errorData = await response.json().catch(() => ({}));
                const errorMessage = errorData.message || `HTTP Error: ${response.status}`;
                console.error('âŒ Backend API Error:', errorMessage);
                throw new Error(errorMessage);
            }

            const result = await response.json();
            console.log('ğŸ“¥ Ù¾Ø§Ø³Ø® JSON Ø§Ø² backend:', result);

            if (!result.success) {
                const errorMessage = result.message || 'Ø®Ø·Ø§ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ Ø¯Ø± API';
                console.error('âŒ Backend API Error:', errorMessage);
                throw new Error(errorMessage);
            }

            if (!result.data || !result.data.text) {
                console.error('âŒ No text in backend response:', result);
                throw new Error('Ù…ØªÙ† ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯');
            }

            const transcript = result.data.text.trim();
            console.log('âœ… Ù…ØªÙ† ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡:', transcript);
            console.log('ğŸ“Š Ø§Ø¹ØªÙ…Ø§Ø¯:', result.data.confidence);

            // Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ù…ØªÙ† Ù…Ø¹Ù†Ø§Ø¯Ø§Ø± Ø¨Ø§Ø´Ø¯
            if (transcript.length < 2) {
                throw new Error('Ù…ØªÙ† ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø®ÛŒÙ„ÛŒ Ú©ÙˆØªØ§Ù‡ Ø§Ø³Øª');
            }

            return transcript;

        } catch (error) {
            console.error('âŒ Ø®Ø·Ø§ÛŒ Ú©Ø§Ù…Ù„ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ†:', {
                error: error,
                message: error instanceof Error ? error.message : 'Ø®Ø·Ø§ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ',
                stack: error instanceof Error ? error.stack : undefined
            });
            throw error;
        }
    }

    // Start recording and return a promise that resolves when manually stopped
    async startRecordingSession(): Promise<{
        stop: () => Promise<string>;
        isRecording: () => boolean;
    }> {
        console.log('ğŸ¤ Ø´Ø±ÙˆØ¹ Ø¬Ù„Ø³Ù‡ Ø¶Ø¨Ø· Ø¨Ø§ Ø³Ø§Ù‡Ø§Ø¨...');

        // Start recording
        await this.startRecording();

        return {
            stop: async () => {
                if (this.isRecording) {
                    const audioBlob = await this.stopRecording();
                    const text = await this.convertToText(audioBlob);
                    return text;
                } else {
                    throw new Error('Ø¶Ø¨Ø· Ø¯Ø± Ø¬Ø±ÛŒØ§Ù† Ù†ÛŒØ³Øª');
                }
            },
            isRecording: () => this.isRecording
        };
    }

    // Complete record and convert process (for backward compatibility)
    async recordAndConvert(maxDuration: number = 30000): Promise<string> {
        console.log('ğŸ¤ Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ú©Ø§Ù…Ù„ Ø¶Ø¨Ø· Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ø§ Ø³Ø§Ù‡Ø§Ø¨...');

        // Start recording
        await this.startRecording();

        return new Promise((resolve, reject) => {
            // Set timeout for maximum recording duration
            const timeout = setTimeout(async () => {
                try {
                    if (this.isRecording) {
                        const audioBlob = await this.stopRecording();
                        const text = await this.convertToText(audioBlob);
                        resolve(text);
                    }
                } catch (error) {
                    reject(error);
                }
            }, maxDuration);

            // For manual stop (in real implementation, you'd have a UI button)
            // For now, we'll auto-stop after the timeout
        });
    }

    // Manual stop method for UI integration
    async stopAndConvert(): Promise<string> {
        if (!this.isRecording) {
            throw new Error('Ø¶Ø¨Ø· Ø¯Ø± Ø¬Ø±ÛŒØ§Ù† Ù†ÛŒØ³Øª');
        }

        try {
            const audioBlob = await this.stopRecording();
            const text = await this.convertToText(audioBlob);
            return text;
        } catch (error) {
            this.cleanup();
            throw error;
        }
    }

    // Clean up resources
    private cleanup(): void {
        if (this.stream) {
            this.stream.getTracks().forEach(track => track.stop());
            this.stream = null;
        }
        this.mediaRecorder = null;
        this.audioChunks = [];
        this.isRecording = false;
    }

    // Get recording status
    getStatus(): {
        isRecording: boolean;
        isSupported: boolean;
        duration: number;
    } {
        return {
            isRecording: this.isRecording,
            isSupported: this.isSupported(),
            duration: this.audioChunks.length * 1000 // Approximate duration
        };
    }

    // Stop current recording (public method)
    async stop(): Promise<void> {
        if (this.isRecording && this.mediaRecorder) {
            this.mediaRecorder.stop();
        }
        this.cleanup();
    }

    // Test microphone access
    async testMicrophone(): Promise<boolean> {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            stream.getTracks().forEach(track => track.stop());
            console.log('âœ… Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† ØªØ£ÛŒÛŒØ¯ Ø´Ø¯');
            return true;
        } catch (error) {
            console.error('âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ†:', error);
            return false;
        }
    }
}

// Export singleton
export const sahabSpeechRecognition = new SahabSpeechRecognition();