import { NextRequest, NextResponse } from 'next/server';

export async function POST(request: NextRequest) {
    try {
        console.log('ğŸ¤ Local Speech API called');

        const formData = await request.formData();
        const audioFile = formData.get('audio') as File;

        if (!audioFile) {
            return NextResponse.json(
                { error: 'ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø§Ø±Ø³Ø§Ù„ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª' },
                { status: 400 }
            );
        }

        console.log('ğŸ“ Audio file received:', {
            name: audioFile.name,
            size: audioFile.size,
            type: audioFile.type
        });

        // For now, we'll implement a simple fallback that returns a placeholder
        // In a real implementation, you could use:
        // 1. A local Whisper model
        // 2. Google Speech-to-Text API
        // 3. Azure Speech Services
        // 4. Other speech recognition services

        // Simulate processing time
        await new Promise(resolve => setTimeout(resolve, 1000));

        // For demo purposes, return a more realistic text based on common commands
        // In production, you'd implement actual speech recognition

        // Try to guess based on audio file size and common patterns
        let predictedText = 'Ú¯Ø²Ø§Ø±Ø´ Ø®ÙˆØ¯Ù…'; // Default to personal report

        // Better heuristic based on file size and duration (larger files might be longer commands)
        if (audioFile.size > 120000) {
            // Very long audio - likely document email command
            predictedText = 'ÙØ§ÛŒÙ„ Ú¯Ø²Ø§Ø±Ø´ Ø±Ùˆ Ø¨Ø±Ø§ÛŒ Ø§Ø­Ù…Ø¯ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†';
        } else if (audioFile.size > 100000) {
            // Long audio - could be employee report or document command
            const random = Math.random();
            if (random > 0.6) {
                predictedText = 'Ø§Ø±Ø³Ø§Ù„ ÙØ§ÛŒÙ„ Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø­Ù…Ø¯';
            } else {
                predictedText = 'Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ø± Ø§Ø­Ù…Ø¯';
            }
        } else if (audioFile.size > 80000) {
            // Medium audio - analysis commands
            const random = Math.random();
            if (random > 0.7) {
                predictedText = 'Ø³Ù†Ø¯ Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ø±Ø§ÛŒ Ø¹Ù„ÛŒ Ø¨ÙØ±Ø³Øª';
            } else if (random > 0.4) {
                predictedText = 'ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´ ÛŒÚ© Ù‡ÙØªÙ‡';
            } else {
                predictedText = 'ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø®ÙˆØ±Ø¯ Ù…Ø´ØªØ±ÛŒØ§Ù†';
            }
        } else if (audioFile.size > 60000) {
            // Short-medium audio - personal reports or simple commands
            const random = Math.random();
            if (random > 0.5) {
                predictedText = 'Ú¯Ø²Ø§Ø±Ø´ Ø®ÙˆØ¯Ù…';
            } else {
                predictedText = 'Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ø± Ø¹Ù„ÛŒ';
            }
        } else {
            // Very short audio - simple commands
            predictedText = 'Ú¯Ø²Ø§Ø±Ø´ Ø®ÙˆØ¯Ù…';
        }

        console.log('ğŸ”® Predicted text based on heuristics:', predictedText);

        console.log('âœ… Local speech processing completed (demo mode)');

        return NextResponse.json({
            success: true,
            text: predictedText,
            provider: 'local-demo',
            language: 'fa',
            confidence: 0.6, // Lower confidence for demo
            note: 'Ø§ÛŒÙ† ÛŒÚ© Ù†Ø³Ø®Ù‡ Ø¢Ø²Ù…Ø§ÛŒØ´ÛŒ Ø§Ø³Øª. Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ ÙˆØ§Ù‚Ø¹ÛŒØŒ Ø³Ø±ÙˆÛŒØ³ ØªØ´Ø®ÛŒØµ Ú¯ÙØªØ§Ø± Ø¨Ø§ÛŒØ¯ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø´ÙˆØ¯.'
        });

    } catch (error) {
        console.error('âŒ Error in Local Speech API:', error);

        return NextResponse.json(
            {
                error: 'Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­Ù„ÛŒ ØµØ¯Ø§',
                details: error instanceof Error ? error.message : 'Ø®Ø·Ø§ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ'
            },
            { status: 500 }
        );
    }
}